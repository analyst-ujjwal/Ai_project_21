ðŸ¤– AI Customer Support Bot â€” Streamlit Edition

An intelligent customer support chatbot built with LangChain and Groq, running entirely in Streamlit. This lightweight prototype helps you simulate a conversational support assistant capable of remembering context and switching between Groqâ€™s cloud models or a local LLaMA backend.

ðŸš€ Features

ðŸ§  LangChain-powered reasoning â€” easily switch between local and hosted LLMs.

âš¡ Groq integration â€” blazing-fast inference with llama-3.1-8b-instant by default.

ðŸ’¬ Persistent chat memory â€” uses a simple SQLite DB to store conversation history.

ðŸª¶ Streamlit-only architecture â€” no backend server needed.

ðŸ”„ Auto model fallback â€” if Groq API is missing, switches to local LLaMA automatically.

ðŸ§° Tech Stack

Streamlit â€” UI + app runner

LangChain â€” LLM orchestration

Groq â€” hosted model inference

SQLite â€” lightweight memory persistence

Python 3.10+